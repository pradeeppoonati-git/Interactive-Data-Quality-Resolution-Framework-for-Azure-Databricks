{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "805b6095-a8d3-4ec8-934b-31a28f4fe565",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%run /Workspace/Users/pradeep.ponati@gmail.com/interactive_framework/00_Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1794c9c6-b606-4ac4-b3bb-8ef504d1eb18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load Bronze data\n",
    "bronze_df = spark.read.format(\"delta\").load(BRONZE_BRIGHTSPACE)\n",
    "print(f\"‚úì Loaded {bronze_df.count()} records from Bronze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b38ba44-3772-4cec-b18f-deb8bcb59e10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# QUALITY CHECK ENGINE FOR BRIGHTSPACE LMS DATA\n",
    "# ============================================================================\n",
    "\n",
    "from pyspark.sql.functions import col, when, lit, concat_ws, row_number, current_timestamp\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"RUNNING QUALITY CHECKS ON BRIGHTSPACE DATA\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total records to check: {bronze_df.count()}\\n\")\n",
    "\n",
    "# Store all violations\n",
    "all_violations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10ceb203-df3d-4230-a852-d678d9b1e866",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CHECK 1: NULL CHECKS - Critical Fields\n",
    "# ============================================================================\n",
    "print(\"‚ñ∂ Check 1: Null values in critical fields...\")\n",
    "\n",
    "critical_fields = ['student_id', 'email', 'enrollment_date']\n",
    "\n",
    "for field in critical_fields:\n",
    "    null_records = bronze_df.filter(col(field).isNull())\n",
    "    \n",
    "    if null_records.count() > 0:\n",
    "        violation_df = null_records \\\n",
    "            .withColumn(\"violation_type\", lit(\"null_value\")) \\\n",
    "            .withColumn(\"violation_severity\", lit(\"critical\")) \\\n",
    "            .withColumn(\"violation_column\", lit(field)) \\\n",
    "            .withColumn(\"violation_description\", lit(f\"Null value in critical field: {field}\"))\n",
    "        \n",
    "        all_violations.append(violation_df)\n",
    "        print(f\"  ‚úó Found {violation_df.count()} null values in '{field}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "725f0234-9e28-46c6-9dd0-b1c9a30b7d5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CHECK 2: INVALID EMAIL FORMAT\n",
    "# ============================================================================\n",
    "print(\"\\n‚ñ∂ Check 2: Email format validation...\")\n",
    "\n",
    "invalid_emails = bronze_df.filter(\n",
    "    col(\"email\").isNotNull() & \n",
    "    ~col(\"email\").rlike(\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\\\.[a-zA-Z]{2,}$\")\n",
    ")\n",
    "\n",
    "if invalid_emails.count() > 0:\n",
    "    violation_df = invalid_emails \\\n",
    "        .withColumn(\"violation_type\", lit(\"format_mismatch\")) \\\n",
    "        .withColumn(\"violation_severity\", lit(\"high\")) \\\n",
    "        .withColumn(\"violation_column\", lit(\"email\")) \\\n",
    "        .withColumn(\"violation_description\", lit(\"Email does not match expected format\"))\n",
    "    \n",
    "    all_violations.append(violation_df)\n",
    "    print(f\"  ‚úó Found {violation_df.count()} invalid email formats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbb84450-93df-4d58-a61c-ec947dc27489",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CHECK 3: NEGATIVE GRADES\n",
    "# ============================================================================\n",
    "print(\"\\n‚ñ∂ Check 3: Grade percentage validation...\")\n",
    "\n",
    "negative_grades = bronze_df.filter(col(\"grade_percentage\") < 0)\n",
    "\n",
    "if negative_grades.count() > 0:\n",
    "    violation_df = negative_grades \\\n",
    "        .withColumn(\"violation_type\", lit(\"out_of_range\")) \\\n",
    "        .withColumn(\"violation_severity\", lit(\"high\")) \\\n",
    "        .withColumn(\"violation_column\", lit(\"grade_percentage\")) \\\n",
    "        .withColumn(\"violation_description\", lit(\"Grade percentage cannot be negative\"))\n",
    "    \n",
    "    all_violations.append(violation_df)\n",
    "    print(f\"  ‚úó Found {violation_df.count()} negative grades\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c4b6a63-94b1-4998-afe3-7486ea9fc6b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CHECK 4: INVALID ATTENDANCE (> 100%)\n",
    "# ============================================================================\n",
    "print(\"\\n‚ñ∂ Check 4: Attendance percentage validation...\")\n",
    "\n",
    "invalid_attendance = bronze_df.filter(col(\"attendance_percentage\") > 100)\n",
    "\n",
    "if invalid_attendance.count() > 0:\n",
    "    violation_df = invalid_attendance \\\n",
    "        .withColumn(\"violation_type\", lit(\"out_of_range\")) \\\n",
    "        .withColumn(\"violation_severity\", lit(\"medium\")) \\\n",
    "        .withColumn(\"violation_column\", lit(\"attendance_percentage\")) \\\n",
    "        .withColumn(\"violation_description\", lit(\"Attendance percentage cannot exceed 100%\"))\n",
    "    \n",
    "    all_violations.append(violation_df)\n",
    "    print(f\"  ‚úó Found {violation_df.count()} invalid attendance percentages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26bb3708-2b80-47ca-8ef7-18d5a7384c4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CHECK 5: LAST ACCESS BEFORE ENROLLMENT\n",
    "# ============================================================================\n",
    "print(\"\\n‚ñ∂ Check 5: Date logic validation...\")\n",
    "\n",
    "invalid_dates = bronze_df.filter(\n",
    "    col(\"last_access_date\").isNotNull() & \n",
    "    col(\"enrollment_date\").isNotNull() &\n",
    "    (col(\"last_access_date\") < col(\"enrollment_date\"))\n",
    ")\n",
    "\n",
    "if invalid_dates.count() > 0:\n",
    "    violation_df = invalid_dates \\\n",
    "        .withColumn(\"violation_type\", lit(\"logic_violation\")) \\\n",
    "        .withColumn(\"violation_severity\", lit(\"high\")) \\\n",
    "        .withColumn(\"violation_column\", lit(\"last_access_date\")) \\\n",
    "        .withColumn(\"violation_description\", lit(\"Last access date cannot be before enrollment date\"))\n",
    "    \n",
    "    all_violations.append(violation_df)\n",
    "    print(f\"  ‚úó Found {violation_df.count()} invalid date sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f187982-b57b-4d0b-920a-54c5f3396248",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CHECK 6: DUPLICATE STUDENT ENROLLMENTS\n",
    "# ============================================================================\n",
    "print(\"\\n‚ñ∂ Check 6: Duplicate detection...\")\n",
    "\n",
    "window_spec = Window.partitionBy(\"student_id\", \"course_code\")\n",
    "duplicates = bronze_df \\\n",
    "    .filter(col(\"student_id\").isNotNull()) \\\n",
    "    .withColumn(\"row_num\", row_number().over(window_spec.orderBy(\"enrollment_date\"))) \\\n",
    "    .filter(col(\"row_num\") > 1)\n",
    "\n",
    "if duplicates.count() > 0:\n",
    "    violation_df = duplicates \\\n",
    "        .withColumn(\"violation_type\", lit(\"duplicate\")) \\\n",
    "        .withColumn(\"violation_severity\", lit(\"medium\")) \\\n",
    "        .withColumn(\"violation_column\", lit(\"student_id,course_code\")) \\\n",
    "        .withColumn(\"violation_description\", lit(\"Duplicate enrollment for same student and course\"))\n",
    "    \n",
    "    all_violations.append(violation_df)\n",
    "    print(f\"  ‚úó Found {violation_df.count()} duplicate enrollments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "391c0a44-9cab-45ec-bb4c-ffbef636574c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMBINE ALL VIOLATIONS & CREATE QUARANTINE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"QUALITY CHECK SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if all_violations:\n",
    "    # Union all violations\n",
    "    quarantine_df = all_violations[0]\n",
    "    for v_df in all_violations[1:]:\n",
    "        quarantine_df = quarantine_df.unionByName(v_df, allowMissingColumns=True)\n",
    "    \n",
    "    from pyspark.sql.functions import monotonically_increasing_id, concat, lit as spark_lit\n",
    "\n",
    "# Add quarantine metadata with UNIQUE ID for each violation\n",
    "    quarantine_df = quarantine_df \\\n",
    "        .withColumn(\"_quarantine_id\", concat(\n",
    "            spark_lit(\"Q_\"),\n",
    "            monotonically_increasing_id().cast(\"string\")\n",
    "        )) \\\n",
    "        .withColumn(\"_quarantine_timestamp\", current_timestamp()) \\\n",
    "        .withColumn(\"resolution_status\", lit(\"pending\")) \\\n",
    "        .withColumn(\"resolved_by\", lit(None).cast(\"string\")) \\\n",
    "        .withColumn(\"resolution_timestamp\", lit(None).cast(\"timestamp\")) \\\n",
    "        .withColumn(\"resolution_action\", lit(None).cast(\"string\")) \\\n",
    "        .withColumn(\"resolution_notes\", lit(None).cast(\"string\"))\n",
    "    \n",
    "    # Get unique violated record IDs\n",
    "    violated_records = quarantine_df.select(\"_record_hash\").distinct()\n",
    "    \n",
    "    # Separate clean records\n",
    "    clean_df = bronze_df.join(violated_records, \"_record_hash\", \"left_anti\")\n",
    "    \n",
    "    total_records = bronze_df.count()\n",
    "    clean_count = clean_df.count()\n",
    "    quarantine_count = quarantine_df.count()\n",
    "    \n",
    "    print(f\"‚úì Clean records: {clean_count} ({clean_count/total_records*100:.1f}%)\")\n",
    "    print(f\"‚úó Quarantined records: {quarantine_count} ({quarantine_count/total_records*100:.1f}%)\")\n",
    "    \n",
    "    # Show violation breakdown\n",
    "    print(\"\\nViolation Breakdown:\")\n",
    "    quarantine_df.groupBy(\"violation_type\", \"violation_severity\") \\\n",
    "        .count() \\\n",
    "        .orderBy(\"violation_severity\", \"count\", ascending=[False, False]) \\\n",
    "        .show(truncate=False)\n",
    "    \n",
    "else:\n",
    "    print(\"‚úì No quality issues found! All data is clean.\")\n",
    "    clean_df = bronze_df\n",
    "    quarantine_df = None\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c8533a2-ede4-4e55-a980-ab49a06f1dc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SAVE RESULTS TO DELTA LAKE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SAVING RESULTS TO DELTA LAKE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save Clean Data to Silver\n",
    "print(f\"\\nüìù Writing clean data to Silver...\")\n",
    "print(f\"   Path: {SILVER_BRIGHTSPACE}\")\n",
    "print(f\"   Records: {clean_df.count()}\")\n",
    "\n",
    "clean_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(SILVER_BRIGHTSPACE)\n",
    "\n",
    "print(f\"‚úì Silver table saved!\")\n",
    "\n",
    "# Save Quarantine Data\n",
    "if quarantine_df is not None:\n",
    "    print(f\"\\nüìù Writing quarantine data...\")\n",
    "    print(f\"   Path: {QUARANTINE_BRIGHTSPACE}\")\n",
    "    print(f\"   Records: {quarantine_df.count()}\")\n",
    "    \n",
    "    quarantine_df.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .save(QUARANTINE_BRIGHTSPACE)\n",
    "    \n",
    "    print(f\"‚úì Quarantine table saved!\")\n",
    "    \n",
    "    # Show sample quarantine records\n",
    "    print(\"\\nüìã Sample Quarantine Records:\")\n",
    "    quarantine_df.select(\n",
    "        \"student_id\", \"email\", \"violation_type\", \n",
    "        \"violation_severity\", \"violation_description\"\n",
    "    ).show(5, truncate=False)\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚úì No quarantine data to save (all records clean)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DATA QUALITY PIPELINE COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"‚úì Bronze ‚Üí Quality Checks ‚Üí Silver + Quarantine\")\n",
    "print(f\"‚úì Ready for interactive resolution!\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Quality_Checks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
